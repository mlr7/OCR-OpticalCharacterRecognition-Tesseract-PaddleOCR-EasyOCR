{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EasyOCR Text Extraction\n",
    "\n",
    "https://pypi.org/project/easyocr/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    }
   ],
   "source": [
    "reader = easyocr.Reader(['en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = reader.readtext('./data_text_images/pg160_kauff1996.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview of EasyOCR ouput format\n",
    "\n",
    "The 'result' object is a list of bounding box locations, corresponding texts, and confidence scores. \n",
    "\n",
    "result[0] has the following content: ([[259, 15], [317, 15], [317, 31], [259, 31]], 'Lecture', 0.9999649906092436)   \n",
    "\n",
    "The text portion of the output can be extracted by indexing into the Python List structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lecture\n",
      "FOURTH LAW WRIT LARGE?\n"
     ]
    }
   ],
   "source": [
    "print(result[0][1])\n",
    "print(result[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lecture\n",
      "FOURTH LAW WRIT LARGE?\n",
      "Attempt\n",
      "10   Explore\n",
      "the    Hypothesis\n",
      "that   the\n",
      "Universe\n",
      "Wholc\n",
      "might\n",
      "Self-Constructing,   Coevolving\n",
      "Community\n",
      "of  Autonomous\n",
      "Agents   that Maximizes\n",
      "the   Sustainable Growth\n",
      "own Total\n",
      "Effective Dimensionality _\n",
      "More\n",
      "Generally,\n",
      "the   Universe Follows\n",
      "Preferred\n",
      "Patb\n",
      "Towards\n",
      "Maximum\n",
      "Complexity\n",
      "With   Exchange\n",
      "Mass\n",
      "and  Space,\n",
      "Because\n",
      "Maximum\n",
      "Complexity Via\n",
      "Growth\n",
      "Into\n",
      "thc\n",
      "Fastest\n",
      "Expanding\n",
      "Adjacent   Possible Maximizes\n",
      "Decoherence\n",
      "Into\n",
      "Classicity\n",
      "Maximum\n",
      "Complexity\n",
      "Attractor   Poised\n",
      "Between\n",
      "Universe\n",
      "Expanding\n",
      "and\n",
      "Contracting_\n",
      "7.0)\n",
      "PROLOCUE:\n",
      "AS 4 BIOLOGIST\n",
      "HAVE\n",
      "AT LEAST SOME\n",
      "CONFIDENCE WHEN THINKING ABOUT THE BIOSPHERE\n",
      "AND EVEN\n",
      "AN EVOLVING ECONOMIC SYSTEM:\n",
      "THE\n",
      "FOLLOWING IS NECESSARILY\n",
      "THE MOST EARLY\n",
      "\"PROTOSCIENCE\" IN THIS DOCUMENT AND IS TO BE\n",
      "TAKEN ONLY AS EFFORTS TO THINK ABOUT SOME\n",
      "POSSIBILITIES\n",
      "brazen\n",
      "cosmology is to\n",
      "countcnanced  only\n",
      "with\n",
      "disclaimers.\n",
      "Among   them_\n",
      "why\n",
      "not?\n",
      "This is an\n",
      "informal\n",
      "\"Investigation_\n",
      "But\n",
      "beyond   this,\n",
      "the previous   six   \"lectures'\n",
      "give  modestly\n",
      "good   grounds\n",
      "think\n",
      "that\n",
      "gencral\n",
      "attractor\n",
      "just  might;\n",
      "govern\n",
      "the\n",
      "coevolution\n",
      "of   lhe ' molecular\n",
      "and   higher   order\n",
      "autonomous  agents\n",
      "that   comprise\n",
      "Lhc\n",
      "biosphere\n",
      "and\n",
      "econosphere\n",
      "Centril\n",
      "the   emerging   picture\n",
      "the\n",
      "possibility\n",
      "that\n",
      "Lnc\n",
      "non-equilibrium _\n",
      "non-ergodic\n",
      "behavior\n",
      "such\n",
      "coupled\n",
      "system\n",
      "of  functional\n",
      "wholes\"\n",
      "will\n",
      "tend to expand\n",
      "the\n",
      "dimensionality of\n",
      "work\n",
      "space'\n",
      "fast\n",
      "as is  SuStainably\n",
      "possible\n",
      "The\n",
      "concepts\n",
      "concerning\n",
      "autonomous\n",
      "agents\n",
      "and   functional\n",
      "closur\n",
      "space\n",
      "tasks   such    that   the  system is\n",
      "autocatalytic\n",
      "and\n",
      "caffies\n",
      "out\n",
      "work\n",
      "are\n",
      "objectively\n",
      "verifiable  properties\n",
      "physical\n",
      "system\n",
      "These\n",
      "new\n",
      "concejIs\n",
      "underlie\n",
      "the\n",
      "tentative  understanding\n",
      "Agents\n",
      "160\n",
      "leap\n",
      "facl,\n",
      "cycles\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(result)):\n",
    "    print(result[i][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tesseract Text Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PaddleOCR Text Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.youtube.com/watch?v=t5xwQguk9XU\n",
    "\n",
    "# https://github.com/nicknochnack/DrugLabelExtraction-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddleocr import PaddleOCR, draw_ocr # main OCR dependencies\n",
    "from matplotlib import pyplot as plt # plot images\n",
    "import cv2 #opencv\n",
    "import os # folder directory navigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup model\n",
    "ocr_model = PaddleOCR(lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_path = os.path.join('.', 'img.jpg')\n",
    "img_path = './kauffmanTable1.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the ocr method on the ocr model\n",
    "result = ocr_model.ocr(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for res in result:\n",
    "    print(res[1][0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Viz PaddleOCR Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting detected components\n",
    "boxes = [res[0] for res in result] # \n",
    "texts = [res[1][0] for res in result]\n",
    "scores = [res[1][1] for res in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying font path for draw_ocr method\n",
    "font_path = os.path.join('PaddleOCR', 'doc', 'fonts', 'latin.ttf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports image\n",
    "img = cv2.imread(img_path) \n",
    "\n",
    "# reorders the color channels\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize our image and detections\n",
    "# resizing display area\n",
    "plt.figure(figsize=(15,15))\n",
    "\n",
    "# draw annotations on image\n",
    "annotated = draw_ocr(img, boxes, texts, scores, font_path=font_path) \n",
    "\n",
    "# show the image using matplotlib\n",
    "plt.imshow(annotated) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
